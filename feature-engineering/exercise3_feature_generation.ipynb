{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model score\n",
      "Training model. Hold on a minute to see the validation score\n",
      "Validation AUC score: 0.9622743228943659\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.feature_engineering.ex3 import *\n",
    "\n",
    "# Create features from   timestamps\n",
    "click_data = pd.read_csv('../input/feature-engineering-data/train_sample.csv', \n",
    "                         parse_dates=['click_time'])\n",
    "click_times = click_data['click_time']\n",
    "clicks = click_data.assign(day=click_times.dt.day.astype('uint8'),\n",
    "                           hour=click_times.dt.hour.astype('uint8'),\n",
    "                           minute=click_times.dt.minute.astype('uint8'),\n",
    "                           second=click_times.dt.second.astype('uint8'))\n",
    "\n",
    "# Label encoding for categorical features\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "for feature in cat_features:\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    clicks[feature] = label_encoder.fit_transform(clicks[feature])\n",
    "    \n",
    "def get_data_splits(dataframe, valid_fraction=0.1):\n",
    "\n",
    "    dataframe = dataframe.sort_values('click_time')\n",
    "    valid_rows = int(len(dataframe) * valid_fraction)\n",
    "    train = dataframe[:-valid_rows * 2]\n",
    "    # valid size == test size, last two sections of the data\n",
    "    valid = dataframe[-valid_rows * 2:-valid_rows]\n",
    "    test = dataframe[-valid_rows:]\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "def train_model(train, valid, test=None, feature_cols=None):\n",
    "    if feature_cols is None:\n",
    "        feature_cols = train.columns.drop(['click_time', 'attributed_time',\n",
    "                                           'is_attributed'])\n",
    "    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
    "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
    "    \n",
    "    param = {'num_leaves': 64, 'objective': 'binary', \n",
    "             'metric': 'auc', 'seed': 7}\n",
    "    num_round = 1000\n",
    "    print(\"Training model. Hold on a minute to see the validation score\")\n",
    "    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n",
    "                    early_stopping_rounds=20, verbose_eval=False)\n",
    "    \n",
    "    valid_pred = bst.predict(valid[feature_cols])\n",
    "    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)\n",
    "    print(f\"Validation AUC score: {valid_score}\")\n",
    "    \n",
    "    if test is not None: \n",
    "        test_pred = bst.predict(test[feature_cols])\n",
    "        test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)\n",
    "        return bst, valid_score, test_score\n",
    "    else:\n",
    "        return bst, valid_score\n",
    "\n",
    "print(\"Baseline model score\")\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "_ = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Add interaction features\n",
    "\n",
    "Here you'll add interaction features for each pair of categorical features (ip, app, device, os, channel). The easiest way to iterate through the pairs of features is with `itertools.combinations`. For each new column, join the values as strings with an underscore, so 13 and 47 would become `\"13_47\"`. As you add the new columns to the dataset, be sure to label encode the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"1_InteractionFeatures\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "interactions = pd.DataFrame(index=clicks.index)\n",
    "\n",
    "for col1, col2 in itertools.combinations(cat_features, 2):\n",
    "    new_col_name = '_'.join([col1, col2])\n",
    "    \n",
    "    # Convert to strings and combine\n",
    "    new_values = clicks[col1].map(str) + \"_\" + clicks[col2].map(str)\n",
    "\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    interactions[new_col_name] = encoder.fit_transform(new_values)\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"1_InteractionFeatures\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> The easiest way to loop through the pairs is with itertools.combinations. Once you have that working, for each pair of columns convert them to strings then you can join them with the `+` operator. It's usually good to join with a symbol like _ inbetween to ensure unique values. Now you should have a column of new categorical values, you can label encoder those and add them to the DataFrame"
      ],
      "text/plain": [
       "Hint: The easiest way to loop through the pairs is with itertools.combinations. Once you have that working, for each pair of columns convert them to strings then you can join them with the `+` operator. It's usually good to join with a symbol like _ inbetween to ensure unique values. Now you should have a column of new categorical values, you can label encoder those and add them to the DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"1_InteractionFeatures\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "\n",
       "    cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
       "    interactions = pd.DataFrame(index=clicks.index)\n",
       "    for col1, col2 in itertools.combinations(cat_features, 2):\n",
       "        new_col_name = '_'.join([col1, col2])\n",
       "        \n",
       "        # Convert to strings and combine\n",
       "        new_values = clicks[col1].map(str) + \"_\" + clicks[col2].map(str)\n",
       "        \n",
       "        encoder = preprocessing.LabelEncoder()\n",
       "        interactions[new_col_name] = encoder.fit_transform(new_values)\n",
       "    \n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "\n",
       "    cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
       "    interactions = pd.DataFrame(index=clicks.index)\n",
       "    for col1, col2 in itertools.combinations(cat_features, 2):\n",
       "        new_col_name = '_'.join([col1, col2])\n",
       "        \n",
       "        # Convert to strings and combine\n",
       "        new_values = clicks[col1].map(str) + \"_\" + clicks[col2].map(str)\n",
       "        \n",
       "        encoder = preprocessing.LabelEncoder()\n",
       "        interactions[new_col_name] = encoder.fit_transform(new_values)\n",
       "    \n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment if you need some guidance\n",
    "q_1.hint()\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with interactions\n",
      "Training model. Hold on a minute to see the validation score\n",
      "Validation AUC score: 0.9626212895350978\n"
     ]
    }
   ],
   "source": [
    "clicks = clicks.join(interactions)\n",
    "print(\"Score with interactions\")\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "_ = train_model(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating numerical features\n",
    "\n",
    "Adding interactions is a quick way to create more categorical features from the data. It's also effective to create new numerical features, you'll typically get a lot of improvement in the model. This takes a bit of brainstorming and experimentation to find features that work well.\n",
    "\n",
    "For these exercises I'm going to have you implement functions that operate on Pandas Series. It can take multiple minutes to run these functions on the entire data set so instead I'll provide feedback by running your function on a smaller dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Number of events in the past six hours\n",
    "\n",
    "The first feature you'll be creating is the number of events from the same IP in the last six hours. It's likely that someone who is visiting often will download the app.\n",
    "\n",
    "Implement a function `count_past_events` that takes a Series of click times (timestamps) and returns another Series with the number of events in the last hour. **Tip:** The `rolling` method is useful for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"2_PastEventsFeature\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_past_events(series, time_window='6H'):\n",
    "        series = pd.Series(series.index, index=series)\n",
    "        # Subtract 1 so the current event isn't counted\n",
    "        past_events = series.rolling(time_window).count() - 1\n",
    "        return past_events\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"2_PastEventsFeature\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> You can get a rolling time window using .rolling(), but first you need to convert the index to a time series. The current row is included in the window, but we want to count all the events before the current row, so be sure to adjust the count."
      ],
      "text/plain": [
       "Hint: You can get a rolling time window using .rolling(), but first you need to convert the index to a time series. The current row is included in the window, but we want to count all the events before the current row, so be sure to adjust the count."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"2_PastEventsFeature\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "\n",
       "    def count_past_events(series, time_window='6H'):\n",
       "        series = pd.Series(series.index, index=series)\n",
       "        # Subtract 1 so the current event isn't counted\n",
       "        past_events = series.rolling(time_window).count() - 1\n",
       "        return past_events\n",
       "    \n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "\n",
       "    def count_past_events(series, time_window='6H'):\n",
       "        series = pd.Series(series.index, index=series)\n",
       "        # Subtract 1 so the current event isn't counted\n",
       "        past_events = series.rolling(time_window).count() - 1\n",
       "        return past_events\n",
       "    \n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment if you need some guidance\n",
    "q_2.hint()\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this can take a while to calculate on the full data, we'll load pre-calculated versions in the cell below to test model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:707: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:734: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:751: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Hold on a minute to see the validation score\n",
      "Validation AUC score: 0.9647255487084245\n"
     ]
    }
   ],
   "source": [
    "# Loading in from saved Parquet file\n",
    "past_events = pd.read_parquet('../input/feature-engineering-data/past_6hr_events.pqt')\n",
    "clicks['ip_past_6hr_counts'] = past_events\n",
    "\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "_ = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_device</th>\n",
       "      <th>ip_os</th>\n",
       "      <th>ip_channel</th>\n",
       "      <th>app_device</th>\n",
       "      <th>app_os</th>\n",
       "      <th>app_channel</th>\n",
       "      <th>device_os</th>\n",
       "      <th>device_channel</th>\n",
       "      <th>os_channel</th>\n",
       "      <th>ip_past_6hr_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>27226</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "      <td>2017-11-06 15:13:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>219682</td>\n",
       "      <td>496314</td>\n",
       "      <td>681060</td>\n",
       "      <td>3631</td>\n",
       "      <td>4100</td>\n",
       "      <td>675</td>\n",
       "      <td>1229</td>\n",
       "      <td>1890</td>\n",
       "      <td>985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>110007</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-06 15:41:07</td>\n",
       "      <td>2017-11-07 08:17:19</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>14419</td>\n",
       "      <td>39852</td>\n",
       "      <td>57863</td>\n",
       "      <td>3581</td>\n",
       "      <td>3849</td>\n",
       "      <td>625</td>\n",
       "      <td>1229</td>\n",
       "      <td>1867</td>\n",
       "      <td>962</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>157</td>\n",
       "      <td>2017-11-06 15:42:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>6955</td>\n",
       "      <td>19603</td>\n",
       "      <td>28875</td>\n",
       "      <td>4196</td>\n",
       "      <td>5045</td>\n",
       "      <td>787</td>\n",
       "      <td>1229</td>\n",
       "      <td>1928</td>\n",
       "      <td>1018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>76270</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "      <td>2017-11-06 15:56:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>300967</td>\n",
       "      <td>792039</td>\n",
       "      <td>1140313</td>\n",
       "      <td>3631</td>\n",
       "      <td>4100</td>\n",
       "      <td>675</td>\n",
       "      <td>1229</td>\n",
       "      <td>1890</td>\n",
       "      <td>985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57862</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "      <td>2017-11-06 15:57:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>274929</td>\n",
       "      <td>722619</td>\n",
       "      <td>1041993</td>\n",
       "      <td>3631</td>\n",
       "      <td>4100</td>\n",
       "      <td>675</td>\n",
       "      <td>1229</td>\n",
       "      <td>1890</td>\n",
       "      <td>985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel          click_time      attributed_time  \\\n",
       "0   27226    3       1  13      120 2017-11-06 15:13:23                  NaN   \n",
       "1  110007   35       1  13       10 2017-11-06 15:41:07  2017-11-07 08:17:19   \n",
       "2    1047    6       1  13      157 2017-11-06 15:42:32                  NaN   \n",
       "3   76270    3       1  13      120 2017-11-06 15:56:17                  NaN   \n",
       "4   57862    3       1  13      120 2017-11-06 15:57:01                  NaN   \n",
       "\n",
       "   is_attributed  day  hour  ...  ip_device   ip_os  ip_channel  app_device  \\\n",
       "0              0    6    15  ...     219682  496314      681060        3631   \n",
       "1              1    6    15  ...      14419   39852       57863        3581   \n",
       "2              0    6    15  ...       6955   19603       28875        4196   \n",
       "3              0    6    15  ...     300967  792039     1140313        3631   \n",
       "4              0    6    15  ...     274929  722619     1041993        3631   \n",
       "\n",
       "   app_os  app_channel  device_os  device_channel  os_channel  \\\n",
       "0    4100          675       1229            1890         985   \n",
       "1    3849          625       1229            1867         962   \n",
       "2    5045          787       1229            1928        1018   \n",
       "3    4100          675       1229            1890         985   \n",
       "4    4100          675       1229            1890         985   \n",
       "\n",
       "   ip_past_6hr_counts  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Features from future information\n",
    "\n",
    "In the last exercise you created a feature that looked at past events. You could also make features that use information from events in the future. Should you use future events or not? \n",
    "\n",
    "Run the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 272, \"questionId\": \"3_FutureInformationQuestion\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> In general, you shouldn't use information from the future. When you're using models like this in a real-world scenario you won't have data from the future. Your model's score will likely be higher when training and testing on historical data, but it will overestimate the performance on real data. I should note that using future data will improve the score on Kaggle competition test data, but avoid it when building machine learning products."
      ],
      "text/plain": [
       "Solution: In general, you shouldn't use information from the future. When you're using models like this in a real-world scenario you won't have data from the future. Your model's score will likely be higher when training and testing on historical data, but it will overestimate the performance on real data. I should note that using future data will improve the score on Kaggle competition test data, but avoid it when building machine learning products."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Time since last event\n",
    "\n",
    "Implement a function `time_diff` that calculates the time since the last event in seconds from a Series of timestamps. This will be ran like so:\n",
    "\n",
    "```python\n",
    "timedeltas = clicks.groupby('ip')['click_time'].transform(time_diff)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_diff(series):\n",
    "    \"\"\" Returns a series with the time since the last timestamp in seconds \"\"\"\n",
    "    return series.diff().dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"4_LastEventFeature\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> Try using the .diff() method on a time series."
      ],
      "text/plain": [
       "Hint: Try using the .diff() method on a time series."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"4_LastEventFeature\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "\n",
       "    def time_diff(series):\n",
       "            return series.diff().dt.total_seconds()\n",
       "    \n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "\n",
       "    def time_diff(series):\n",
       "            return series.diff().dt.total_seconds()\n",
       "    \n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment if you need some guidance\n",
    "q_4.hint()\n",
    "q_4.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"4_LastEventFeature\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll again load pre-computed versions of the data, which match what your function would return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:707: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:734: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:751: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Hold on a minute to see the validation score\n",
      "Validation AUC score: 0.9651116624672765\n"
     ]
    }
   ],
   "source": [
    "# Loading in from saved Parquet file\n",
    "past_events = pd.read_parquet('../input/feature-engineering-data/time_deltas.pqt')\n",
    "clicks['past_events_6hr'] = past_events\n",
    "\n",
    "train, valid, test = get_data_splits(clicks.join(past_events))\n",
    "_ = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Number of previous app downloads\n",
    "\n",
    "It's likely that if a visitor downloaded an app previously, it'll affect the likelihood they'll download one again. Implement a function `previous_attributions` that returns a Series with the number of times an app has been download (`'is_attributed' == 1`) before the current event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"5_PreviousAttributionsFeature\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def previous_attributions(series):\n",
    "    # Subtracting raw values so I don't count the current event\n",
    "    sums = series.expanding(min_periods=2).sum() - series\n",
    "    return sums\n",
    "\n",
    "# Check your answer\n",
    "q_5.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"5_PreviousAttributionsFeature\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> Here you want a window that always starts at the first row but expands as you get further in the data. You can use the `.expanding` methods for this. Also, the current row is included in the window, so you'll need to subtract that off as well"
      ],
      "text/plain": [
       "Hint: Here you want a window that always starts at the first row but expands as you get further in the data. You can use the `.expanding` methods for this. Also, the current row is included in the window, so you'll need to subtract that off as well"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 272, \"questionId\": \"5_PreviousAttributionsFeature\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "\n",
       "    def previous_attributions(series):\n",
       "        # Subtracting raw values so I don't count the current event\n",
       "        sums = series.expanding(min_periods=2).sum() - series\n",
       "        return sums\n",
       "    \n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "\n",
       "    def previous_attributions(series):\n",
       "        # Subtracting raw values so I don't count the current event\n",
       "        sums = series.expanding(min_periods=2).sum() - series\n",
       "        return sums\n",
       "    \n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment if you need some guidance\n",
    "q_5.hint()\n",
    "q_5.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again loading pre-computed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:707: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:734: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:751: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "# Loading in from saved Parquet file\n",
    "past_events = pd.read_parquet('../input/feature-engineering-data/downloads.pqt')\n",
    "clicks['ip_past_6hr_counts'] = past_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. Hold on a minute to see the validation score\n",
      "Validation AUC score: 0.965236652054989\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = get_data_splits(clicks)\n",
    "_ = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Tree-based vs Neural Network Models\n",
    "\n",
    "So far we've been using LightGBM, a tree-based model. Would these features we've generated work well for neural networks as well as tree-based models?\n",
    "\n",
    "Run the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 272, \"questionId\": \"6_TreeVsDLModels\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> The features themselves will work for either model. However, numerical inputs to neural networks need to be standardized first. That is, the features need to be scaled such that they have 0 mean and a standard deviation of 1. This can be done using sklearn.preprocessing.StandardScaler."
      ],
      "text/plain": [
       "Solution: The features themselves will work for either model. However, numerical inputs to neural networks need to be standardized first. That is, the features need to be scaled such that they have 0 mean and a standard deviation of 1. This can be done using sklearn.preprocessing.StandardScaler."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "q_6.solution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
